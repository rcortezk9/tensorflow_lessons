{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_SkimLit_nlp_milestone_project_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMaXSPsmwCuMAofIzCqlJv/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcortezk9/tensorflow_lessons/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX5l83rANpdX"
      },
      "source": [
        "**Reminder**\n",
        "* Press SHIFT+CMD+SPACE to read the docstring\n",
        "* Search for it\n",
        "* Ask (don't forget the Discord chat!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc-WPID5EUGf"
      },
      "source": [
        "\n",
        "# Milestone Project 2: SkimLit ðŸ“„ðŸ”¥\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
        "\n",
        "The paper we're replicating (the source of the dataset that we'll be using) is available here: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "And reading through the paper above, we see that the model architecture that they use to achieve their best results is available here: https://arxiv.org/abs/1612.05251\n",
        "\n",
        "ðŸ“– Resource: If you want to find the ground truth for this notebook (with lots of diagrams and text annotations) see the GitHub: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoJ3cCCMD-bS",
        "outputId": "e5c7953a-93af-414e-de36-d342b0535943"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-f5f2cf91-6f8c-a67e-30fb-39f1e54cab35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhBoO33eGIob"
      },
      "source": [
        "## Get data\n",
        "\n",
        "Since we'll be replicating the paper above (PubMed 200k RCT), let's download the dataset they used.\n",
        "\n",
        "We can do so from the authors GitHub: https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL1f5RiIJ3kQ",
        "outputId": "acb108c0-bb6b-43ec-970d-1c9614aafb5c"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Total 30 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTyuKBhnLUQ1",
        "outputId": "2f33fe7d-a5a5-487b-c253-2a55977f8702"
      },
      "source": [
        "# Check what files are in the PubMed_20K dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKaPA5zVLf7l"
      },
      "source": [
        "# Start our experiments using the 20k dataset with numbers replaced by \"@\" sign\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaEKiCDL09O"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "Now we've got some text data, it's time to become one with it.\n",
        "\n",
        "And one of the best ways to become one with the data is to...\n",
        "\n",
        "Visualize, visualize, visualize\n",
        "\n",
        "So with that in mind, let's write a function to read in all of the lines of a target text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1QRk0FCL_XC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}