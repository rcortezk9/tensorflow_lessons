{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MOzs94xo4Qiyz5Ku3CSjt3N3bfsgCN-w",
      "authorship_tag": "ABX9TyOvlorthDkzZjGJ50oP6m9l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcortezk9/tensorflow_lessons/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa7KsosFNw9V"
      },
      "source": [
        "# Introduction to NLP Fundameantals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving infomration out of natural language (could be seqeuences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CpaWCmTNbLS"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO-iPp_kOq69",
        "outputId": "28d1a30d-9230-490a-b263-7a3ca30a6adf"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d0c06900-da96-e051-9bb4-3e1cb0f7a646)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWmS4YQ7O0G5"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sXkMIFRPAkN",
        "outputId": "64d6009c-a451-4d37-ca49-a194c5451094"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-02 00:33:16--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-02 00:33:16 (103 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fypAJoJcPM_Z"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as diaster or not diaster).\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK2s-5EBP9av",
        "outputId": "da2cb2ee-75be-4ca3-f4cc-5f2a0d2e087b"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-02 00:33:18--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 142.250.141.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-06-02 00:33:18 (110 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1RYDl1uQgMJ"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "hn3GsYojRAZU",
        "outputId": "abd6bfb5-e626-4948-a248-e4e629009631"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5RFBI_MbSKZa",
        "outputId": "830f0bf3-57cd-417d-df4d-5b9b0b2d9618"
      },
      "source": [
        "train_df['text'][0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "oPliHwQpSaFl",
        "outputId": "82d8e8aa-d732-4616-8042-764d1c623023"
      },
      "source": [
        "# Shuffle Training DataFrame\n",
        "\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uj42WfCuS037",
        "outputId": "fadff152-f285-4dee-bfc0-adde1de30755"
      },
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIgkLNEQTDAz",
        "outputId": "631c126d-802c-401a-c7e5-59876b566350"
      },
      "source": [
        "# How many examples of class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBaXShxNTK7k",
        "outputId": "8f718e1b-d97b-4d2a-cdb8-9772d5ed1c97"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSNmWmuDTw4K",
        "outputId": "1ee7e3ef-3383-454a-ee50-c29eac23d958"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create radom indexes not higher\n",
        "for row in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f'Target\" {target}', '(real diaster)' if target > 0 else '(not real diaster)')\n",
        "  print(f'text:\\n{text}\\n')\n",
        "  print('---\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target\" 0 (not real diaster)\n",
            "text:\n",
            "Check these out: http://t.co/rOI2NSmEJJ http://t.co/3Tj8ZjiN21 http://t.co/YDUiXEfIpE http://t.co/LxTjc87KLS #nsfw\n",
            "\n",
            "---\n",
            "\n",
            "Target\" 1 (real diaster)\n",
            "text:\n",
            "Anyone travelling Aberystwyth-Shrewsbury right now there's been an incident. Services at a halt just outside Shrews. Ambulance on scene.\n",
            "\n",
            "---\n",
            "\n",
            "Target\" 1 (real diaster)\n",
            "text:\n",
            "#Boulder deputies are waiting for the bomb squad to detonate grenade like this one found in Stearns lake today http://t.co/7cADM3lNkO\n",
            "\n",
            "---\n",
            "\n",
            "Target\" 0 (not real diaster)\n",
            "text:\n",
            "Psalms 34:22 The Lord redeemeth the soul of his servants: and none of them that trust in him shall be desolate.\n",
            "\n",
            "---\n",
            "\n",
            "Target\" 1 (real diaster)\n",
            "text:\n",
            "Visting Georgina at The Drowned Rat Cafe.....awful view!! http://t.co/pYLFb3tI9U\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRqj4YagVF2q"
      },
      "source": [
        " ### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he2gzrtYtDAl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLUJU0Jzt8dU"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_senteces, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                              train_df_shuffled['target'].to_numpy(),\n",
        "                                              test_size=0.1, # use 10% of training data for valid\n",
        "                                              random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9O0PlLWu6Fw",
        "outputId": "67778407-b26e-466f-b3de-04ab9f9314a5"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_senteces), len(val_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ0fKR0cvcE4",
        "outputId": "2f6fc49e-e148-410c-fb6a-9d076d588f1d"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHhz3kGGx4Cc"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenziation - direct mapping of token (a token could be a word or a character) to number\n",
        "* Embedding - create a matrix of a feature vector for each token ( the size of the feature vector can be defined and this embedding can be learned)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhd1j67mx9mF"
      },
      "source": [
        "### Text vectorization (tokenization)\n",
        "\n",
        "The processing of each sample contains the following steps:\n",
        "\n",
        "1. standardize each sample (usually lowercasing + punctuation stripping)\n",
        "2. split each sample into substrings (usually words)\n",
        "3. recombine substrings into tokens (usually ngrams)\n",
        "4. index tokens (associate a unique int value with each token)\n",
        "5. transform each sample using this index, either into a vector of ints or a dense float vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjViw5MK_71b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    split='whitespace',\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode='int', # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7T66XRnAFxu",
        "outputId": "978f12df-d629-4b0b-892d-18c3fb2604b9"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv_gLwoIDx0V"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # nax number of words to have in our vacabulary\n",
        "max_length = 15 # max lenght our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL8-ZF1QEg_5"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GdeaC6yFZuK",
        "outputId": "4d4b3da3-1b40-4334-b379-7416f036b29a"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz-mZytKFtSR",
        "outputId": "4b4d19b9-e4e9-4c6f-e5c7-5cf75d4675e2"
      },
      "source": [
        "# Choose a random sentence from the training dataaset and tokenize it\n",
        "random_sentences = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentences}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentences])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " Beautiful Sweet Avalanche Faith and Akito roses with lots of frothy gyp. http://t.co/RaqUpzFkJY #weddinghour http://t.co/quNxocXCgA      \n",
            "\n",
            "Vectorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 588, 2273,  611, 3013,    7,    1, 4717,   14, 1504,    6,    1,\n",
              "           1,    1, 6867,    1]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iay2T18uGhTF",
        "outputId": "37055dc0-338d-46c6-c31a-20f4aebeb0b9"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El6hbMG7H4mi"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use TensorFlow's embedding layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The parameters we care most about for our embedding layers:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO0auPKfIyAm",
        "outputId": "befd3e8a-9d0c-4eb1-ecc4-c86932864830"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # output shape\n",
        "                             embeddings_initializer='uniform',\n",
        "                             input_length=max_length)\n",
        "\n",
        "embedding"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7fca9a2ae650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpwVI8yKKeEv",
        "outputId": "b77aafcf-e36e-488d-bed7-3c72a31aa83d"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentences = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentences}\\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentences]))\n",
        "sample_embed"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " I... I might buy my esoteric weapon for astrologian...        \n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.0285439 ,  0.04031492,  0.00113427, ..., -0.00766066,\n",
              "          0.0360538 , -0.00917203],\n",
              "        [-0.0285439 ,  0.04031492,  0.00113427, ..., -0.00766066,\n",
              "          0.0360538 , -0.00917203],\n",
              "        [-0.00677948,  0.02782787,  0.00474662, ...,  0.01060538,\n",
              "         -0.02341626,  0.03493178],\n",
              "        ...,\n",
              "        [ 0.00773741,  0.02807636, -0.03458194, ..., -0.02125982,\n",
              "          0.04502323, -0.04285364],\n",
              "        [ 0.00773741,  0.02807636, -0.03458194, ..., -0.02125982,\n",
              "          0.04502323, -0.04285364],\n",
              "        [ 0.00773741,  0.02807636, -0.03458194, ..., -0.02125982,\n",
              "          0.04502323, -0.04285364]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpK_Vg7ELSfd",
        "outputId": "e73f7e3e-cb23-4a59-bf05-ae38b6628cb5"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentences"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.0285439 ,  0.04031492,  0.00113427,  0.04223133, -0.04799992,\n",
              "         0.02103516, -0.02374721,  0.01629753,  0.04877311,  0.02036983,\n",
              "         0.04552747, -0.03704147, -0.00526301,  0.01595474, -0.03177464,\n",
              "        -0.01919272, -0.00034157,  0.01222533,  0.04955305,  0.03007178,\n",
              "        -0.03894997, -0.0365678 , -0.01719228, -0.02269487, -0.0274287 ,\n",
              "        -0.04059023,  0.00368262, -0.01755977,  0.00977797,  0.03324571,\n",
              "         0.0067461 , -0.00710719, -0.03406072,  0.02419963,  0.01282242,\n",
              "        -0.02773329, -0.04041959, -0.04745649, -0.03269601, -0.03976572,\n",
              "         0.01671579,  0.03066261,  0.04053428, -0.04237909, -0.0008475 ,\n",
              "        -0.01451429, -0.04468071,  0.04945214, -0.02040044,  0.02057001,\n",
              "         0.01312813, -0.01168835,  0.02049178,  0.04439833,  0.03466361,\n",
              "         0.03637353, -0.03944635,  0.02600935,  0.01776573,  0.02504757,\n",
              "         0.00544318, -0.02773308, -0.00887801,  0.01895971, -0.01416158,\n",
              "         0.03185615,  0.0301748 , -0.03099316,  0.02420044, -0.00704533,\n",
              "         0.0134529 ,  0.02419803,  0.0418563 ,  0.00083128, -0.04636602,\n",
              "         0.01109285, -0.03715364,  0.00126258,  0.02345225,  0.03215971,\n",
              "        -0.03432107,  0.03749894, -0.00045101, -0.00836145,  0.04007269,\n",
              "        -0.0406247 ,  0.02555897,  0.04798912,  0.03945998,  0.03793854,\n",
              "         0.01030814, -0.04182326,  0.01605995, -0.00710326,  0.00601081,\n",
              "         0.03918732,  0.03297282,  0.04602598, -0.04194786,  0.03410406,\n",
              "         0.04192429, -0.03954823,  0.0440361 , -0.02071956,  0.017291  ,\n",
              "         0.01632574, -0.00018952,  0.04842551, -0.00512856,  0.01736493,\n",
              "        -0.01482831, -0.04758586, -0.02658224,  0.00887708, -0.03241275,\n",
              "         0.03443474, -0.00123609,  0.03561657,  0.00892569, -0.02712313,\n",
              "         0.01328013, -0.04242763, -0.01263604,  0.04620922,  0.0302983 ,\n",
              "        -0.00766066,  0.0360538 , -0.00917203], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'I... I might buy my esoteric weapon for astrologian...')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k2X3XPwMAoa"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a serivews of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline), this is form Sklearn ML map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we going to apporach all of these?\n",
        "\n",
        "Use the standard steps in modelling with tensorflow:\n",
        "\n",
        "* Create a model\n",
        "* Build a model \n",
        "* Fit a model\n",
        "* Evaluate our model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9uGHFRzUMcb"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> 🔑 **Note:** It's common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7dcX4o2Ye8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1fee376-0f9a-4882-eae8-ab2255003405"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    ('tfidf', TfidfVectorizer()), # convert words to number using tfidf\n",
        "                    ('clf', MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCyuN3S5bFgL",
        "outputId": "82711123-6ed2-4e22-dd55-5a5bcd5f1ce0"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_senteces, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa6j734XbmGu",
        "outputId": "4d20bde9-61f2-4c10-c604-a64fa9125067"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_senteces)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u4-RcOYb_2L"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's predictions with different meics every time, however, this will be cumbersome and could easily be fixed with a function...\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "> For a deep overview of many different evaluation methods, see the sklearn documentation: https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nICmUUhDJr4S"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classifiction model.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall, and f1-scrore using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "  model_results = {'accuracy': model_accuracy,\n",
        "                   'precision': model_precision,\n",
        "                   'recall': model_recall,\n",
        "                   'f1': model_f1}\n",
        "  return model_results                   "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWmJhBowM3cW",
        "outputId": "b295e8f8-1b0b-4e22-d10e-b3ca7268d5cb"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(val_labels, baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MGWNpn6NSCQ"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Y8f6CAWciE"
      },
      "source": [
        "# Create a tensorboard callback (need to crate a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = 'model_logs'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnYx_oq_Wyin"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1, ), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) #turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x) # create the output layer, want binary outputs so use sigmoid\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_dense')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxfDpGWZN6p"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWuTkIwHZwDb",
        "outputId": "1ceab290-3aab-4949-ab6e-2f98e333d4fb"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                             y=train_labels,\n",
        "                             epochs=5,\n",
        "                             validation_data=(val_senteces, val_labels),\n",
        "                             callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_1_dense\")])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210602-003326\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 18ms/step - loss: 0.6151 - accuracy: 0.6898 - val_loss: 0.5394 - val_accuracy: 0.7546\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.4436 - accuracy: 0.8152 - val_loss: 0.4691 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3481 - accuracy: 0.8596 - val_loss: 0.4563 - val_accuracy: 0.7940\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2846 - accuracy: 0.8902 - val_loss: 0.4616 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2387 - accuracy: 0.9130 - val_loss: 0.4795 - val_accuracy: 0.7887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw2hBKC1aa14",
        "outputId": "0b404256-6a5b-48aa-ce7c-0a14cabd4323"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_senteces, val_labels)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4795021712779999, 0.7887139320373535]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSqDJLTYavCC",
        "outputId": "d6cc810e-9ad9-40a8-e084-aa2bf7405faa"
      },
      "source": [
        "# Make some predictions and evalaute those\n",
        "model_1_pred_probs = model_1.predict(val_senteces)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEWdhunea_MN",
        "outputId": "778ceb3e-fb94-4255-aeb6-56db69d97d3b"
      },
      "source": [
        "# Look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.34180197], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63td8i8pbNZ1",
        "outputId": "b6597eaa-2616-4dc6-f608-b699555649cd"
      },
      "source": [
        "# Look at the first 10 predictions\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.34180197],\n",
              "       [0.8206264 ],\n",
              "       [0.9978542 ],\n",
              "       [0.10077392],\n",
              "       [0.11474748],\n",
              "       [0.9316818 ],\n",
              "       [0.90891874],\n",
              "       [0.99378705],\n",
              "       [0.96226746],\n",
              "       [0.22340459]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb-cp6XJcxe0",
        "outputId": "9c244942-0684-4584-81f1-8c6067d32afd"
      },
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7joc73eda-r",
        "outputId": "978313ef-4858-473e-e4da-2fcdcc70f11a"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(val_labels, model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.87139107611549,\n",
              " 'f1': 0.7853694687698636,\n",
              " 'precision': 0.7948464726843409,\n",
              " 'recall': 0.7887139107611548}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2gDybEMd2qh",
        "outputId": "a209004a-212a-42d8-f206-3a73d47a9fcf"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgsPJJTWeCNK",
        "outputId": "aabeb7e0-def8-4b3e-f409-c7753d6f1721"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSMEPKdsePBj"
      },
      "source": [
        "## Visualizing learnded embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I49xy8ddfVGN",
        "outputId": "491ee70a-24d7-40df-9f78-f00901c4248b"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XzbZdj-GJCx",
        "outputId": "5b201fd0-6467-43bf-d5e7-e4b997e86741"
      },
      "source": [
        "# Model 1 summary \n",
        "model_1.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG-kZpqwGRRk",
        "outputId": "a98c13f3-7bad-482a-f64f-a123f5c0a7bf"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numberical representations of each token in our training data, which have been learne3d for ~5 epochs)\n",
        "embed_weights = model_1.get_layer('embedding').get_weights()[0]\n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim(output_dime of our embedding layer)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoK0O49Hlav"
      },
      "source": [
        "Now we've got the embedding matrix our model has lwarned to represent our tokens, lets' see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: http://projector.tensorflow.org/\n",
        "\n",
        "And Tensorflow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQW4QTzBGzVd"
      },
      "source": [
        "# Create embedding files (we go this from TensorFlow's word embeddings documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UqNg-0WKJPJE",
        "outputId": "33416b49-8613-463d-b899-ba73c97ebff3"
      },
      "source": [
        "# Download files from Colab to upload to projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4615003d-da3e-4b24-b131-bc6028aa9c0e\", \"vectors.tsv\", 15383258)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_89892037-cece-4478-bee4-e775cdd19ac3\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjNMxiapKbhd"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequuence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the re3presentation of a previous input to adi the representation of a later input.\n",
        "\n",
        "> 📖 **Resources:** If you want an overview of the internals of a recurrent neural network, see the following:\n",
        "* MIT's sequence modelling lecture https://youtube/qjrad0V0uJE\n",
        "* Chris Olah's intro to LSTMs: https://colab.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "* Andrej Karpathy's the unreasonable effectiveness of recurrent neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omMIcdWpOLMH"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our sturcuture of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1IfOVpCPLLm"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1, ), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # When you're stacking RNN cells together, you need to set return_sequences=True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='model_2_LSTM')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_39KExbQsbZ",
        "outputId": "b7ee7b5e-c838-428c-e400-35e62eaf82f3"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvR4ci_rU40a"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrbOZaUcVtra",
        "outputId": "f8f0d250-0acc-4d80-e606-986a2c23888a"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_senteces, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, 'model_2_LTSM')])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LTSM/20210602-003348\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 23ms/step - loss: 0.2220 - accuracy: 0.9168 - val_loss: 0.5926 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1552 - accuracy: 0.9423 - val_loss: 0.6474 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1301 - accuracy: 0.9515 - val_loss: 0.7574 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1047 - accuracy: 0.9610 - val_loss: 0.7763 - val_accuracy: 0.7835\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0860 - accuracy: 0.9682 - val_loss: 0.7744 - val_accuracy: 0.7703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpGJm588WVtv",
        "outputId": "962f69c4-5199-4e14-fc7c-909c65a91714"
      },
      "source": [
        "# Make predictions with LTSM model\n",
        "model_2_pred_probs = model_2.predict(val_senteces)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7351824 ],\n",
              "       [0.93011606],\n",
              "       [0.99949443],\n",
              "       [0.17328809],\n",
              "       [0.00116948],\n",
              "       [0.99645245],\n",
              "       [0.95420694],\n",
              "       [0.99971896],\n",
              "       [0.99949527],\n",
              "       [0.56351566]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMj7UfliWlCv",
        "outputId": "463f49e7-e3c1-4664-ff0b-acca6a4cf460"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3Ej2I6EW2jl",
        "outputId": "8abb92d1-7196-4b50-e778-b07817da38f0"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.770505544081278,\n",
              " 'precision': 0.7708000639796135,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElM4-VkYXISn",
        "outputId": "5eb8abd9-5a0d-4c09-afa3-9e2eaddfa978"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJapuHF3XThQ"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or **gated recurrent unit.**\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTL1_CY4aVQf"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "\n",
        "inputs = layers.Input(shape=(1, ), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x) # When you're stacking RNN cells together, you need to set return_sequences=True\n",
        "# x = layers.LSTM(64, return_sequences=True)(x)\n",
        "# x = layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name='model_3_GRU')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vvL7MWPK1Xv",
        "outputId": "9e45db22-cd75-49e9-d482-b26b669dde44"
      },
      "source": [
        "# Get a summary\n",
        "model_3.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OISF8P96L8yb"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtT0EVZmR3i2",
        "outputId": "878340ab-35d0-4549-ca26-2d1b89f5dc5c"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_senteces, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, 'model_3_GRU')])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU /20210602-011510\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 21ms/step - loss: 0.1571 - accuracy: 0.9388 - val_loss: 0.6869 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0848 - accuracy: 0.9710 - val_loss: 0.7909 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.0682 - accuracy: 0.9731 - val_loss: 0.9634 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0607 - accuracy: 0.9743 - val_loss: 1.1467 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.0536 - accuracy: 0.9750 - val_loss: 1.1036 - val_accuracy: 0.7808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcAcF8nXSeKI",
        "outputId": "17c94a36-0d53-45c1-a335-e3d27fc02aac"
      },
      "source": [
        "# Make some predictions with our GRU mode\n",
        "model_3_pred_probs = model_3.predict(val_senteces)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.7024148e-03],\n",
              "       [7.2653884e-01],\n",
              "       [9.9989271e-01],\n",
              "       [1.0730946e-01],\n",
              "       [1.2865308e-04],\n",
              "       [9.9984515e-01],\n",
              "       [9.7686678e-01],\n",
              "       [9.9994373e-01],\n",
              "       [9.9991465e-01],\n",
              "       [9.1170502e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvO9Bsl4StRn",
        "outputId": "02f99669-a0bd-47fb-d054-96d0ddb31000"
      },
      "source": [
        "# Convert model 3 pred probs to labels (apples to apples)\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEIB7oeTTLsJ",
        "outputId": "db93ebe7-2e02-4409-cd32-f54053fc8aad"
      },
      "source": [
        "# Calculate model 3 results\n",
        "model_3_results = calculate_results(val_labels, model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1': 0.7794817733933848,\n",
              " 'precision': 0.781486692298758,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE7B4xEETj2H"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidirectional RNN goes form right to left as well as left to right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX31v5qhaccc"
      },
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1, ), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name='model_4_bidirectional')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuMP-Lw0eky6",
        "outputId": "352aa37f-272f-4672-d7ab-8fca4b3cb244"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QSkKGe3ewk8"
      },
      "source": [
        "# Compile model\n",
        "model_4.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WhK2O7Kf3GO",
        "outputId": "47a04f18-533b-4cb1-e7bf-cb9075a2bf56"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_senteces, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, 'model_4_bidirectional')])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210602-021513\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 24ms/step - loss: 0.1077 - accuracy: 0.9676 - val_loss: 0.9140 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0517 - accuracy: 0.9783 - val_loss: 1.2455 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0465 - accuracy: 0.9785 - val_loss: 1.3866 - val_accuracy: 0.7756\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0427 - accuracy: 0.9801 - val_loss: 1.3532 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0420 - accuracy: 0.9793 - val_loss: 1.3781 - val_accuracy: 0.7690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RozX8QKgNtv",
        "outputId": "91d4e52a-fa8e-4e3f-fca3-167a99792859"
      },
      "source": [
        "# Make predictions with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_senteces)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3857370e-01],\n",
              "       [7.3026413e-01],\n",
              "       [9.9998569e-01],\n",
              "       [1.2536296e-01],\n",
              "       [1.8218314e-05],\n",
              "       [9.9983299e-01],\n",
              "       [8.1989682e-01],\n",
              "       [9.9999225e-01],\n",
              "       [9.9997735e-01],\n",
              "       [9.9796945e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCeVgmmigjF1",
        "outputId": "a1bf52c7-2fff-4579-8c1e-d090d0a8dd3d"
      },
      "source": [
        "# Convert pred probs to pred lables\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cijBGG-Pg7A8",
        "outputId": "87f67f19-8cfe-413c-85d1-b05f5a81b6d2"
      },
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.768063295978387,\n",
              " 'precision': 0.7689137548517897,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiKvjYu3hQVk",
        "outputId": "2200bff5-c583-4bd5-e1a0-7fcead3759b8"
      },
      "source": [
        "model_3_results"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1': 0.7794817733933848,\n",
              " 'precision': 0.781486692298758,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iVd2ihWhX6A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}